{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f077fc1-8608-412b-84b3-c4e2505cdcd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: TensorFlow in ./venv/lib/python3.11/site-packages (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./venv/lib/python3.11/site-packages (from TensorFlow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./venv/lib/python3.11/site-packages (from TensorFlow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in ./venv/lib/python3.11/site-packages (from TensorFlow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./venv/lib/python3.11/site-packages (from TensorFlow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./venv/lib/python3.11/site-packages (from TensorFlow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in ./venv/lib/python3.11/site-packages (from TensorFlow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./venv/lib/python3.11/site-packages (from TensorFlow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in ./venv/lib/python3.11/site-packages (from TensorFlow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./venv/lib/python3.11/site-packages (from TensorFlow) (3.3.0)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.11/site-packages (from TensorFlow) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./venv/lib/python3.11/site-packages (from TensorFlow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./venv/lib/python3.11/site-packages (from TensorFlow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.11/site-packages (from TensorFlow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./venv/lib/python3.11/site-packages (from TensorFlow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./venv/lib/python3.11/site-packages (from TensorFlow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./venv/lib/python3.11/site-packages (from TensorFlow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./venv/lib/python3.11/site-packages (from TensorFlow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./venv/lib/python3.11/site-packages (from TensorFlow) (1.63.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in ./venv/lib/python3.11/site-packages (from TensorFlow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in ./venv/lib/python3.11/site-packages (from TensorFlow) (3.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./venv/lib/python3.11/site-packages (from TensorFlow) (0.37.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in ./venv/lib/python3.11/site-packages (from TensorFlow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./venv/lib/python3.11/site-packages (from astunparse>=1.6.0->TensorFlow) (0.43.0)\n",
      "Requirement already satisfied: rich in ./venv/lib/python3.11/site-packages (from keras>=3.0.0->TensorFlow) (13.7.1)\n",
      "Requirement already satisfied: namex in ./venv/lib/python3.11/site-packages (from keras>=3.0.0->TensorFlow) (0.0.8)\n",
      "Requirement already satisfied: optree in ./venv/lib/python3.11/site-packages (from keras>=3.0.0->TensorFlow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->TensorFlow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->TensorFlow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->TensorFlow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->TensorFlow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./venv/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->TensorFlow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./venv/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->TensorFlow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./venv/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->TensorFlow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./venv/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->TensorFlow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./venv/lib/python3.11/site-packages (from rich->keras>=3.0.0->TensorFlow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./venv/lib/python3.11/site-packages (from rich->keras>=3.0.0->TensorFlow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./venv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->TensorFlow) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: Keras in ./venv/lib/python3.11/site-packages (3.3.3)\n",
      "Requirement already satisfied: absl-py in ./venv/lib/python3.11/site-packages (from Keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.11/site-packages (from Keras) (1.26.4)\n",
      "Requirement already satisfied: rich in ./venv/lib/python3.11/site-packages (from Keras) (13.7.1)\n",
      "Requirement already satisfied: namex in ./venv/lib/python3.11/site-packages (from Keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in ./venv/lib/python3.11/site-packages (from Keras) (3.11.0)\n",
      "Requirement already satisfied: optree in ./venv/lib/python3.11/site-packages (from Keras) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in ./venv/lib/python3.11/site-packages (from Keras) (0.3.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in ./venv/lib/python3.11/site-packages (from optree->Keras) (4.11.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./venv/lib/python3.11/site-packages (from rich->Keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./venv/lib/python3.11/site-packages (from rich->Keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./venv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->Keras) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pillow in ./venv/lib/python3.11/site-packages (10.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: NumPy in ./venv/lib/python3.11/site-packages (1.26.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.11/site-packages (4.66.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: jupyterlab in ./venv/lib/python3.11/site-packages (4.1.8)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in ./venv/lib/python3.11/site-packages (from jupyterlab) (2.0.4)\n",
      "Requirement already satisfied: httpx>=0.25.0 in ./venv/lib/python3.11/site-packages (from jupyterlab) (0.27.0)\n",
      "Requirement already satisfied: ipykernel>=6.5.0 in ./venv/lib/python3.11/site-packages (from jupyterlab) (6.29.4)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in ./venv/lib/python3.11/site-packages (from jupyterlab) (3.1.4)\n",
      "Requirement already satisfied: jupyter-core in ./venv/lib/python3.11/site-packages (from jupyterlab) (5.7.2)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in ./venv/lib/python3.11/site-packages (from jupyterlab) (2.2.5)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in ./venv/lib/python3.11/site-packages (from jupyterlab) (2.14.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in ./venv/lib/python3.11/site-packages (from jupyterlab) (2.27.1)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in ./venv/lib/python3.11/site-packages (from jupyterlab) (0.2.4)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.11/site-packages (from jupyterlab) (24.0)\n",
      "Requirement already satisfied: tornado>=6.2.0 in ./venv/lib/python3.11/site-packages (from jupyterlab) (6.4)\n",
      "Requirement already satisfied: traitlets in ./venv/lib/python3.11/site-packages (from jupyterlab) (5.14.3)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.11/site-packages (from httpx>=0.25.0->jupyterlab) (4.3.0)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.11/site-packages (from httpx>=0.25.0->jupyterlab) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.11/site-packages (from httpx>=0.25.0->jupyterlab) (1.0.5)\n",
      "Requirement already satisfied: idna in ./venv/lib/python3.11/site-packages (from httpx>=0.25.0->jupyterlab) (3.7)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.11/site-packages (from httpx>=0.25.0->jupyterlab) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab) (0.14.0)\n",
      "Requirement already satisfied: appnope in ./venv/lib/python3.11/site-packages (from ipykernel>=6.5.0->jupyterlab) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in ./venv/lib/python3.11/site-packages (from ipykernel>=6.5.0->jupyterlab) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in ./venv/lib/python3.11/site-packages (from ipykernel>=6.5.0->jupyterlab) (1.8.1)\n",
      "Requirement already satisfied: ipython>=7.23.1 in ./venv/lib/python3.11/site-packages (from ipykernel>=6.5.0->jupyterlab) (8.24.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in ./venv/lib/python3.11/site-packages (from ipykernel>=6.5.0->jupyterlab) (8.6.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in ./venv/lib/python3.11/site-packages (from ipykernel>=6.5.0->jupyterlab) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in ./venv/lib/python3.11/site-packages (from ipykernel>=6.5.0->jupyterlab) (1.6.0)\n",
      "Requirement already satisfied: psutil in ./venv/lib/python3.11/site-packages (from ipykernel>=6.5.0->jupyterlab) (5.9.8)\n",
      "Requirement already satisfied: pyzmq>=24 in ./venv/lib/python3.11/site-packages (from ipykernel>=6.5.0->jupyterlab) (26.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.11/site-packages (from jinja2>=3.0.3->jupyterlab) (2.1.5)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./venv/lib/python3.11/site-packages (from jupyter-core->jupyterlab) (4.2.1)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in ./venv/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (23.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in ./venv/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in ./venv/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.5.3)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in ./venv/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.16.4)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in ./venv/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (5.10.4)\n",
      "Requirement already satisfied: overrides>=5.0 in ./venv/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in ./venv/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.20.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in ./venv/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in ./venv/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in ./venv/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.0)\n",
      "Requirement already satisfied: babel>=2.10 in ./venv/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (2.15.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in ./venv/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (0.9.25)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in ./venv/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (4.22.0)\n",
      "Requirement already satisfied: requests>=2.31 in ./venv/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (2.31.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in ./venv/lib/python3.11/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (21.2.0)\n",
      "Requirement already satisfied: decorator in ./venv/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./venv/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.19.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in ./venv/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./venv/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (2.18.0)\n",
      "Requirement already satisfied: stack-data in ./venv/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.6.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in ./venv/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (4.11.0)\n",
      "Requirement already satisfied: pexpect>4.3 in ./venv/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (4.9.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./venv/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./venv/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./venv/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./venv/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (0.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.11/site-packages (from jupyter-client>=6.1.12->ipykernel>=6.5.0->jupyterlab) (2.9.0.post0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in ./venv/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in ./venv/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (6.0.1)\n",
      "Requirement already satisfied: rfc3339-validator in ./venv/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in ./venv/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in ./venv/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in ./venv/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (6.1.0)\n",
      "Requirement already satisfied: defusedxml in ./venv/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in ./venv/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in ./venv/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (3.0.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in ./venv/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.10.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in ./venv/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.1)\n",
      "Requirement already satisfied: tinycss2 in ./venv/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in ./venv/lib/python3.11/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.19.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.11/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.11/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab) (2.2.1)\n",
      "Requirement already satisfied: ptyprocess in ./venv/lib/python3.11/site-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->jupyterlab) (0.7.0)\n",
      "Requirement already satisfied: six>=1.9.0 in ./venv/lib/python3.11/site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.16.0)\n",
      "Requirement already satisfied: webencodings in ./venv/lib/python3.11/site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.5.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in ./venv/lib/python3.11/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.8.4)\n",
      "Requirement already satisfied: fqdn in ./venv/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (1.5.1)\n",
      "Requirement already satisfied: isoduration in ./venv/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in ./venv/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (2.4)\n",
      "Requirement already satisfied: uri-template in ./venv/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in ./venv/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (1.13)\n",
      "Requirement already satisfied: wcwidth in ./venv/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.2.13)\n",
      "Requirement already satisfied: cffi>=1.0.1 in ./venv/lib/python3.11/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./venv/lib/python3.11/site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (2.5)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./venv/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./venv/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in ./venv/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.2.2)\n",
      "Requirement already satisfied: pycparser in ./venv/lib/python3.11/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (2.22)\n",
      "Requirement already satisfied: arrow>=0.15.0 in ./venv/lib/python3.11/site-packages (from isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in ./venv/lib/python3.11/site-packages (from arrow>=0.15.0->isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (2.9.0.20240316)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install TensorFlow\n",
    "!pip install Keras\n",
    "!pip install pillow\n",
    "!pip install NumPy\n",
    "!pip install tqdm\n",
    "!pip install jupyterlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ba0fa7-2fa3-4779-ad03-f915083961a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6197e28-9583-4ad1-a727-711260db0a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Keras-Preprocessing in ./venv/lib/python3.11/site-packages (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.9.1 in ./venv/lib/python3.11/site-packages (from Keras-Preprocessing) (1.26.4)\n",
      "Requirement already satisfied: six>=1.9.0 in ./venv/lib/python3.11/site-packages (from Keras-Preprocessing) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install Keras-Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cb9485f-36ee-416a-892a-72bdab01167c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./venv/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in ./venv/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ef2adaf-63aa-4c88-8168-ee8be0e8a9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot-ng~=2.0.0 in ./venv/lib/python3.11/site-packages (2.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.1 in ./venv/lib/python3.11/site-packages (from pydot-ng~=2.0.0) (3.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pydot-ng~=2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb010f84-d435-451a-bc7b-0b0709c8f4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-15 02:06:06.726998: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4506364ad30473a81d315091cd6032f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import string\n",
    "from pickle import dump\n",
    "from pickle import load\n",
    "from keras.applications.xception import Xception #to get pre-trained model Xception\n",
    "from keras.applications.xception import preprocess_input\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer #for text tokenization\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Concatenate\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense#Keras to build our CNN and LSTM\n",
    "from keras.layers import LSTM, Embedding, Dropout\n",
    "from tqdm.notebook import tqdm #to check loop progress\n",
    "tqdm().pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42add367-082b-483f-8066-089b7610793f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of descriptions = 8092\n",
      "Length of vocabulary =  8763\n"
     ]
    }
   ],
   "source": [
    "# Load the document file into memory\n",
    "def load_fp(filename):\n",
    "    # Open file to read\n",
    "    file = open(filename, 'r')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "# get all images with their captions\n",
    "def img_capt(filename):\n",
    "    file = load_fp(filename)\n",
    "    captions = file.split(\"\\n\")\n",
    "    descriptions ={}\n",
    "    for caption in captions[:-1]:\n",
    "        img, caption = caption.split(\"\\t\")\n",
    "        # print(f\"img {img} -- caption {caption}\")\n",
    "        if img[:-2] not in descriptions: # -2 because we are skipping the number at the end of the image name\n",
    "            descriptions[img[:-2]] = [caption]\n",
    "        else:\n",
    "            descriptions[img[:-2]].append(caption)\n",
    "    return descriptions\n",
    "\n",
    "#Data cleaning function will convert all upper case alphabets to lowercase, removing punctuations and words containing numbers\n",
    "def txt_clean(captions):\n",
    "    table = str.maketrans('','',string.punctuation)\n",
    "    for img,caps in captions.items():\n",
    "      for i,img_caption in enumerate(caps):\n",
    "        img_caption.replace(\"-\",\" \")\n",
    "        descp = img_caption.split()\n",
    "        #uppercase to lowercase\n",
    "        descp = [wrd.lower() for wrd in descp]\n",
    "        #remove punctuation from each token\n",
    "        descp = [wrd.translate(table) for wrd in descp]\n",
    "        #remove hanging 's and a\n",
    "        descp = [wrd for wrd in descp if(len(wrd)>1)] # len of `s is 2 but ' is removed in punctuation step\n",
    "        #remove words containing numbers with them\n",
    "        descp = [wrd for wrd in descp if(wrd.isalpha())]\n",
    "        #converting back to string\n",
    "        img_caption = \" \".join(descp)\n",
    "        captions[img][i]= img_caption\n",
    "        #print(f\"image {img} caption  - {captions[img][i]}\")\n",
    "    return captions\n",
    "\n",
    "def txt_vocab(descriptions):\n",
    "    # To build vocab of all unique words\n",
    "    vocab = set()\n",
    "    for key in descriptions.keys():\n",
    "        [vocab.update(d.split()) for d in descriptions[key]]\n",
    "        # for d in descriptions[key]:\n",
    "        #     [vocab.update(d.split())]\n",
    "        #     print(d.split())\n",
    "    return vocab\n",
    "\n",
    "#To save all descriptions in one file\n",
    "def save_descriptions(descriptions, filename):\n",
    "    lines = list()\n",
    "    for key, desc_list in descriptions.items():\n",
    "      for desc in desc_list:\n",
    "        lines.append(key + \"\\t\" + desc )\n",
    "        data = \"\\n\".join(lines)\n",
    "        file = open(filename,\"w\")\n",
    "        file.write(data)\n",
    "        file.close()\n",
    "# Set these path according to project folder in you system\n",
    "dataset_text = \"Flickr8k_text\"\n",
    "dataset_images = \"Flicker8k_Dataset\"\n",
    "#to prepare our text data\n",
    "filename = dataset_text + \"/\" + \"Flickr8k.token.txt\"\n",
    "#loading the file that contains all data\n",
    "#map them into descriptions dictionary \n",
    "descriptions = img_capt(filename)\n",
    "print(\"Length of descriptions =\" ,len(descriptions))\n",
    "#cleaning the descriptions\n",
    "clean_descriptions = txt_clean(descriptions)\n",
    "#to build vocabulary\n",
    "vocabulary = txt_vocab(clean_descriptions)\n",
    "print(\"Length of vocabulary = \", len(vocabulary))\n",
    "#saving all descriptions in one file\n",
    "save_descriptions(clean_descriptions, \"descriptions.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c75ea230-1c6c-45a5-98fa-ec85be14dd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set SSL \n",
    "\n",
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "169571d7-81e5-4388-b6dc-98151caa5eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(dirc):\n",
    "        model = Xception( include_top=False, pooling='avg' )\n",
    "        features = {}\n",
    "        for pic in tqdm(os.listdir(dirc)):\n",
    "                   file = dirc + \"/\" + pic\n",
    "                   image = Image.open(file)\n",
    "                   image = image.resize((299,299))\n",
    "                   image = np.expand_dims(image, axis=0)\n",
    "                   #image = preprocess_input(image)\n",
    "                   image = image/127.5 # Image normalization 255/2 = 127.5\n",
    "                   image = image - 1.0 # Converting it to between range -1 to 1\n",
    "                   feature = model.predict(image)\n",
    "                   features[pic] = feature\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "593c1014-ecb2-474b-af5a-c4ae68b53bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run only once\n",
    "\n",
    "# #2048 feature vector\n",
    "# features = extract_features(dataset_images)\n",
    "# dump(features, open(\"features.p\",\"wb\"))\n",
    "# #to directly load the features from the pickle file.\n",
    "# features = load(open(\"features.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78569cbe-5072-44ef-babc-ea9f7eb012ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' child in pink dress is climbing up set of stairs in an entry way ', ' girl going into wooden building ', ' little girl climbing into wooden playhouse ', ' little girl climbing the stairs to her playhouse ', ' little girl in pink dress going into wooden cabin ']\n"
     ]
    }
   ],
   "source": [
    "#load the data\n",
    "def load_photos(filename):\n",
    "    file = load_fp(filename)\n",
    "    photos = file.split(\"\\n\")[:-1]\n",
    "    return photos\n",
    "def load_clean_descriptions(filename, photos):\n",
    "    #loading clean_descriptions\n",
    "    file = load_fp(filename)\n",
    "    descriptions = {}\n",
    "    for line in file.split(\"\\n\"):\n",
    "        words = line.split()\n",
    "        if len(words)<2: # To skip img desc pair with no desc since len of list will be just 1 then. But it should be <2  not <1\n",
    "            continue\n",
    "        image, image_caption = words[0], words[1:]\n",
    "        if image in photos: \n",
    "            if image not in descriptions:\n",
    "                descriptions[image] = []\n",
    "            desc = f' {\" \".join(image_caption)} '\n",
    "            # desc = ' ' + \" \".join(image_caption) + ' '\n",
    "            # print(desc)\n",
    "            descriptions[image].append(desc)\n",
    "    print(descriptions[\"1000268201_693b08cb0e.jpg\"])            \n",
    "    return descriptions\n",
    "def load_features(photos):\n",
    "    #loading all featuresq\n",
    "    all_features = load(open(\"features.p\",\"rb\"))\n",
    "    #selecting only needed features\n",
    "    features = {k:all_features[k] for k in photos}\n",
    "    return features\n",
    "filename = dataset_text + \"/\" + \"Flickr_8k.trainImages.txt\"\n",
    "#train = loading_data(filename)\n",
    "train_imgs = load_photos(filename)\n",
    "train_descriptions = load_clean_descriptions(\"descriptions.txt\", train_imgs)\n",
    "train_features = load_features(train_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfa2b301-1095-482f-a6df-2abaa54b8634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7577\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "#convert dictionary to clear list of descriptions\n",
    "def dict_to_list(descriptions):\n",
    "    all_desc = []\n",
    "    for key in descriptions.keys():\n",
    "       [all_desc.append(d) for d in descriptions[key]]\n",
    "    # print(f\"Length of all_desc {len(all_desc)}\")    \n",
    "    return all_desc\n",
    "#creating tokenizer class\n",
    "#this will vectorise text corpus\n",
    "#each integer will represent token in dictionary\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "def create_tokenizer(descriptions):\n",
    "    desc_list = dict_to_list(descriptions)\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(desc_list)\n",
    "    return tokenizer\n",
    "# give each word an index, and store that into tokenizer.p pickle file\n",
    "tokenizer = create_tokenizer(train_descriptions)\n",
    "dump(tokenizer, open('tokenizer.p', 'wb'))\n",
    "# print(tokenizer.word_index)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(vocab_size) #The size of our vocabulary is 7577 words.\n",
    "#calculate maximum length of descriptions to decide the model structure parameters.\n",
    "def max_length(descriptions):\n",
    "    desc_list = dict_to_list(descriptions)\n",
    "    return max(len(d.split()) for d in desc_list)\n",
    "max_length = max_length(descriptions)\n",
    "print(max_length) #Max_length of description is 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d7c5c22-cdfc-403a-8289-28667b467de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feature' 'feature' 'feature' 'feature' 'feature' 'feature' 'feature'\n",
      " 'feature' 'feature' 'feature' 'feature' 'feature' 'feature']\n",
      "\n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0   40]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0   40    1]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0   40    1   85]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    40    1   85  167]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0   40\n",
      "     1   85  167    4]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0   40    1\n",
      "    85  167    4  115]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0   40    1   85\n",
      "   167    4  115   53]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0   40    1   85  167\n",
      "     4  115   53  391]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0   40    1   85  167    4\n",
      "   115   53  391    9]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0   40    1   85  167    4  115\n",
      "    53  391    9  392]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0   40    1   85  167    4  115   53\n",
      "   391    9  392    1]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0   40    1   85  167    4  115   53  391\n",
      "     9  392    1   25]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0   40    1   85  167    4  115   53  391    9\n",
      "   392    1   25 4472]]\n",
      "\n",
      " [[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(13,) (13, 32) (13, 7577)\n"
     ]
    }
   ],
   "source": [
    "seq = tokenizer.texts_to_sequences([' child in pink dress is climbing up set of stairs in an entry way '])[0]\n",
    "x_1, x_2, y = list(), list(), list()\n",
    "for i in range(1, len(seq)):\n",
    "    # divide into input and output pair\n",
    "    in_seq, out_seq = seq[:i], seq[i]\n",
    "    # pad input sequence\n",
    "    in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
    "    # encode output sequence\n",
    "    out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "    # store\n",
    "    x_1.append(\"feature\")\n",
    "    x_2.append(in_seq)\n",
    "    y.append(out_seq)\n",
    "x_1, x_2, y = np.array(x_1), np.array(x_2), np.array(y)\n",
    "print(f\"{x_1}\\n\\n{x_2}\\n\\n {y}\")\n",
    "print(x_1.shape, x_2.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c344a469-1bd7-45c6-b4ba-8327392af20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37, 2048) (37, 32) (37, 7577)\n"
     ]
    }
   ],
   "source": [
    "#data generator, used by model.fit_generator()\n",
    "def data_generator(descriptions, features, tokenizer, max_length):\n",
    "    while True:\n",
    "        for key, description_list in descriptions.items():\n",
    "            #retrieve photo features\n",
    "            feature = features[key][0]\n",
    "            inp_image, inp_seq, op_word = create_sequences(tokenizer, max_length, description_list, feature)\n",
    "            yield ((inp_image, inp_seq), op_word)\n",
    "def create_sequences(tokenizer, max_length, desc_list, feature):\n",
    "    x_1, x_2, y = list(), list(), list()\n",
    "    # move through each description for the image\n",
    "    for desc in desc_list:\n",
    "        # encode the sequence\n",
    "        seq = tokenizer.texts_to_sequences([desc])[0]\n",
    "        # divide one sequence into various X,y pairs\n",
    "        for i in range(1, len(seq)):\n",
    "            # divide into input and output pair\n",
    "            in_seq, out_seq = seq[:i], seq[i]\n",
    "            # pad input sequence\n",
    "            in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
    "            # encode output sequence\n",
    "            out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "            # store\n",
    "            x_1.append(feature)\n",
    "            x_2.append(in_seq)\n",
    "            y.append(out_seq)\n",
    "    return np.array(x_1), np.array(x_2), np.array(y)\n",
    "#To check the shape of the input and output for your model\n",
    "[a,b],c = next(data_generator(descriptions, train_features, tokenizer, max_length))\n",
    "print(a.shape, b.shape, c.shape)\n",
    "#((47, 2048), (47, 32), (47, 7577))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9837719a-afed-4959-8fa6-7ab63a7889dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "# define the captioning model\n",
    "def define_model(vocab_size, max_length):\n",
    "    # features from the CNN model compressed from 2048 to 256 nodes\n",
    "    inputs1 = Input(shape=(2048,))\n",
    "    fe1 = Dropout(0.5)(inputs1)\n",
    "    fe2 = Dense(256, activation='relu')(fe1)\n",
    "    # LSTM sequence model\n",
    "    inputs2 = Input(shape=(max_length,))\n",
    "    se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
    "    se2 = Dropout(0.5)(se1)\n",
    "    se3 = LSTM(256)(se2)\n",
    "    # Merging both models\n",
    "    decoder1 = Concatenate()([fe2, se3])\n",
    "    decoder2 = Dense(256, activation='relu')(decoder1)\n",
    "    outputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
    "    # merge it [image, seq] [word]\n",
    "    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    # summarize model\n",
    "    print(model.summary())\n",
    "    plot_model(model, to_file='model.png', show_shapes=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ec5f278-2975-421b-8057-57ed917afda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  6000\n",
      "Descriptions: train= 6000\n",
      "Photos: train= 6000\n",
      "Vocabulary Size: 7577\n",
      "Description Length:  32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,939,712</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ not_equal_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7577</span>)      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,947,289</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │  \u001b[38;5;34m1,939,712\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m524,544\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m525,312\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ not_equal_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m131,328\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7577\u001b[0m)      │  \u001b[38;5;34m1,947,289\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,068,185</span> (19.33 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,068,185\u001b[0m (19.33 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,068,185</span> (19.33 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,068,185\u001b[0m (19.33 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n",
      "model <Functional name=functional_5, built=True>\n",
      "\u001b[1m6000/6000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m765s\u001b[0m 127ms/step - loss: 5.4091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6000/6000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m953s\u001b[0m 159ms/step - loss: 4.0154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6000/6000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1084s\u001b[0m 181ms/step - loss: 3.6392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6000/6000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1595s\u001b[0m 266ms/step - loss: 3.4212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  70/6000\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29:15\u001b[0m 296ms/step - loss: 3.2002"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m generator \u001b[38;5;241m=\u001b[39m data_generator(train_descriptions, train_features, tokenizer, max_length)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#model.fit([x1,x2],y)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Image Caption Generator/venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/Image Caption Generator/venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m~/Documents/Image Caption Generator/venv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/Image Caption Generator/venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Documents/Image Caption Generator/venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Image Caption Generator/venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Image Caption Generator/venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Documents/Image Caption Generator/venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/Documents/Image Caption Generator/venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Image Caption Generator/venv/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/Documents/Image Caption Generator/venv/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train our model\n",
    "print('Dataset: ', len(train_imgs))\n",
    "print('Descriptions: train=', len(train_descriptions))\n",
    "print('Photos: train=', len(train_features))\n",
    "print('Vocabulary Size:', vocab_size)\n",
    "print('Description Length: ', max_length)\n",
    "model = define_model(vocab_size, max_length)\n",
    "print(f\"model {model}\")\n",
    "epochs = 10\n",
    "steps = len(train_descriptions)\n",
    "# creating a directory named models to save our models\n",
    "# os.mkdir(\"models\")\n",
    "for i in range(epochs):\n",
    "    generator = data_generator(train_descriptions, train_features, tokenizer, max_length)\n",
    "    #model.fit([x1,x2],y)\n",
    "    model.fit(generator, epochs=1, steps_per_epoch=steps, verbose=1)\n",
    "    model.save(f\"models/model_{i}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1cf0b4-9e15-4f81-b7d3-051e551b7e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53cce2a6-44a0-4574-ab14-8e994f28490a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in ./venv/lib/python3.11/site-packages (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.11/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.11/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./venv/lib/python3.11/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.21 in ./venv/lib/python3.11/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.11/site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in ./venv/lib/python3.11/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./venv/lib/python3.11/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51161abe-2eaf-482a-a353-43c7a918da9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "# ap = argparse.ArgumentParser()\n",
    "# ap.add_argument('-i', '--image', required=True, help=\"Image Path\")\n",
    "# args = vars(ap.parse_args())\n",
    "# img_path = args['image']\n",
    "def extract_features(filename, model):\n",
    "    try:\n",
    "        image = Image.open(filename)\n",
    "    except:\n",
    "        print(\"ERROR: Can't open image! Ensure that image path and extension is correct\")\n",
    "    image = image.resize((299,299))\n",
    "    image = np.array(image)\n",
    "    # for 4 channels images, we need to convert them into 3 channels\n",
    "    if image.shape[2] == 4:\n",
    "        image = image[..., :3]\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = image/127.5\n",
    "    image = image - 1.0\n",
    "    feature = model.predict(image)\n",
    "    return feature\n",
    "def word_for_id(integer, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return word\n",
    "    return None\n",
    "def generate_desc(model, tokenizer, photo, max_length):\n",
    "    in_text = 'start'\n",
    "    for i in range(max_length):\n",
    "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
    "        pred = model.predict([photo,sequence], verbose=0)\n",
    "        pred = np.argmax(pred)\n",
    "        word = word_for_id(pred, tokenizer)\n",
    "        if word is None:\n",
    "            break\n",
    "        in_text += ' ' + word\n",
    "        if word == 'end':\n",
    "            break\n",
    "    return in_text\n",
    "max_length = 32\n",
    "img_path = \"Flicker8k_Dataset/55470226_52ff517151.jpg\"\n",
    "tokenizer = load(open(\"tokenizer.p\",\"rb\"))\n",
    "model = load_model('models/model_9.h5')\n",
    "xception_model = Xception(include_top=False, pooling=\"avg\")\n",
    "photo = extract_features(img_path, xception_model)\n",
    "img = Image.open(img_path)\n",
    "description = generate_desc(model, tokenizer, photo, max_length)\n",
    "print(\"nn\")\n",
    "print(description)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "092cf73d-993b-42a7-8b1a-99350c141be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: absl-py==2.1.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: anyio==4.3.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (4.3.0)\n",
      "Requirement already satisfied: appnope==0.1.4 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (0.1.4)\n",
      "Requirement already satisfied: argon2-cffi==23.1.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (23.1.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings==21.2.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (21.2.0)\n",
      "Requirement already satisfied: arrow==1.3.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: asttokens==2.4.1 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (2.4.1)\n",
      "Requirement already satisfied: astunparse==1.6.3 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (1.6.3)\n",
      "Requirement already satisfied: async-lru==2.0.4 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (2.0.4)\n",
      "Requirement already satisfied: attrs==23.2.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (23.2.0)\n",
      "Requirement already satisfied: Babel==2.15.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (2.15.0)\n",
      "Requirement already satisfied: beautifulsoup4==4.12.3 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (4.12.3)\n",
      "Requirement already satisfied: bleach==6.1.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 13)) (6.1.0)\n",
      "Requirement already satisfied: certifi==2024.2.2 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 14)) (2024.2.2)\n",
      "Requirement already satisfied: cffi==1.16.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 15)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer==3.3.2 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 16)) (3.3.2)\n",
      "Requirement already satisfied: comm==0.2.2 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 17)) (0.2.2)\n",
      "Requirement already satisfied: debugpy==1.8.1 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 18)) (1.8.1)\n",
      "Requirement already satisfied: decorator==5.1.1 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 19)) (5.1.1)\n",
      "Requirement already satisfied: defusedxml==0.7.1 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 20)) (0.7.1)\n",
      "Requirement already satisfied: executing==2.0.1 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 21)) (2.0.1)\n",
      "Requirement already satisfied: fastjsonschema==2.19.1 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 22)) (2.19.1)\n",
      "Requirement already satisfied: flatbuffers==24.3.25 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 23)) (24.3.25)\n",
      "Requirement already satisfied: fqdn==1.5.1 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 24)) (1.5.1)\n",
      "Requirement already satisfied: gast==0.5.4 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 25)) (0.5.4)\n",
      "Requirement already satisfied: google-pasta==0.2.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 26)) (0.2.0)\n",
      "Requirement already satisfied: graphviz==0.20.3 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 27)) (0.20.3)\n",
      "Requirement already satisfied: grpcio==1.63.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 28)) (1.63.0)\n",
      "Requirement already satisfied: h11==0.14.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 29)) (0.14.0)\n",
      "Requirement already satisfied: h5py==3.11.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 30)) (3.11.0)\n",
      "Requirement already satisfied: httpcore==1.0.5 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 31)) (1.0.5)\n",
      "Requirement already satisfied: httpx==0.27.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 32)) (0.27.0)\n",
      "Requirement already satisfied: idna==3.7 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 33)) (3.7)\n",
      "Requirement already satisfied: ipykernel==6.29.4 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 34)) (6.29.4)\n",
      "Requirement already satisfied: ipython==8.24.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 35)) (8.24.0)\n",
      "Requirement already satisfied: ipywidgets==8.1.2 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 36)) (8.1.2)\n",
      "Requirement already satisfied: isoduration==20.11.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 37)) (20.11.0)\n",
      "Requirement already satisfied: jedi==0.19.1 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 38)) (0.19.1)\n",
      "Requirement already satisfied: Jinja2==3.1.4 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 39)) (3.1.4)\n",
      "Requirement already satisfied: json5==0.9.25 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 40)) (0.9.25)\n",
      "Requirement already satisfied: jsonpointer==2.4 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 41)) (2.4)\n",
      "Requirement already satisfied: jsonschema==4.22.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 42)) (4.22.0)\n",
      "Requirement already satisfied: jsonschema-specifications==2023.12.1 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 43)) (2023.12.1)\n",
      "Requirement already satisfied: jupyter-events==0.10.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 44)) (0.10.0)\n",
      "Requirement already satisfied: jupyter-lsp==2.2.5 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 45)) (2.2.5)\n",
      "Requirement already satisfied: jupyter_client==8.6.1 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 46)) (8.6.1)\n",
      "Requirement already satisfied: jupyter_core==5.7.2 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 47)) (5.7.2)\n",
      "Requirement already satisfied: jupyter_server==2.14.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 48)) (2.14.0)\n",
      "Requirement already satisfied: jupyter_server_terminals==0.5.3 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 49)) (0.5.3)\n",
      "Requirement already satisfied: jupyterlab==4.1.8 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 50)) (4.1.8)\n",
      "Requirement already satisfied: jupyterlab_pygments==0.3.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 51)) (0.3.0)\n",
      "Requirement already satisfied: jupyterlab_server==2.27.1 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 52)) (2.27.1)\n",
      "Requirement already satisfied: jupyterlab_widgets==3.0.10 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 53)) (3.0.10)\n",
      "Requirement already satisfied: keras==3.3.3 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 54)) (3.3.3)\n",
      "Requirement already satisfied: Keras-Preprocessing==1.1.2 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 55)) (1.1.2)\n",
      "Requirement already satisfied: libclang==18.1.1 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 56)) (18.1.1)\n",
      "Requirement already satisfied: Markdown==3.6 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 57)) (3.6)\n",
      "Requirement already satisfied: markdown-it-py==3.0.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 58)) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe==2.1.5 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 59)) (2.1.5)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 60)) (0.1.7)\n",
      "Requirement already satisfied: mdurl==0.1.2 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 61)) (0.1.2)\n",
      "Requirement already satisfied: mistune==3.0.2 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 62)) (3.0.2)\n",
      "Requirement already satisfied: ml-dtypes==0.3.2 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 63)) (0.3.2)\n",
      "Requirement already satisfied: namex==0.0.8 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 64)) (0.0.8)\n",
      "Requirement already satisfied: nbclient==0.10.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 65)) (0.10.0)\n",
      "Requirement already satisfied: nbconvert==7.16.4 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 66)) (7.16.4)\n",
      "Requirement already satisfied: nbformat==5.10.4 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 67)) (5.10.4)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 68)) (1.6.0)\n",
      "Requirement already satisfied: notebook==7.1.3 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 69)) (7.1.3)\n",
      "Requirement already satisfied: notebook_shim==0.2.4 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 70)) (0.2.4)\n",
      "Requirement already satisfied: numpy==1.26.4 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 71)) (1.26.4)\n",
      "Requirement already satisfied: opt-einsum==3.3.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 72)) (3.3.0)\n",
      "Requirement already satisfied: optree==0.11.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 73)) (0.11.0)\n",
      "Requirement already satisfied: overrides==7.7.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 74)) (7.7.0)\n",
      "Requirement already satisfied: packaging==24.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 75)) (24.0)\n",
      "Requirement already satisfied: pandas==2.2.2 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 76)) (2.2.2)\n",
      "Requirement already satisfied: pandocfilters==1.5.1 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 77)) (1.5.1)\n",
      "Requirement already satisfied: parso==0.8.4 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 78)) (0.8.4)\n",
      "Requirement already satisfied: pexpect==4.9.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 79)) (4.9.0)\n",
      "Requirement already satisfied: pillow==10.3.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 80)) (10.3.0)\n",
      "Requirement already satisfied: platformdirs==4.2.1 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 81)) (4.2.1)\n",
      "Requirement already satisfied: prometheus_client==0.20.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 82)) (0.20.0)\n",
      "Requirement already satisfied: prompt-toolkit==3.0.43 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 83)) (3.0.43)\n",
      "Requirement already satisfied: protobuf==4.25.3 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 84)) (4.25.3)\n",
      "Requirement already satisfied: psutil==5.9.8 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 85)) (5.9.8)\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 86)) (0.7.0)\n",
      "Requirement already satisfied: pure-eval==0.2.2 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 87)) (0.2.2)\n",
      "Requirement already satisfied: pycparser==2.22 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 88)) (2.22)\n",
      "Requirement already satisfied: pydot==2.0.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 89)) (2.0.0)\n",
      "Requirement already satisfied: pydot-ng==2.0.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 90)) (2.0.0)\n",
      "Requirement already satisfied: Pygments==2.18.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 91)) (2.18.0)\n",
      "Requirement already satisfied: pyparsing==3.1.2 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 92)) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 93)) (2.9.0.post0)\n",
      "Requirement already satisfied: python-json-logger==2.0.7 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 94)) (2.0.7)\n",
      "Requirement already satisfied: pytz==2024.1 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 95)) (2024.1)\n",
      "Requirement already satisfied: PyYAML==6.0.1 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 96)) (6.0.1)\n",
      "Requirement already satisfied: pyzmq==26.0.3 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 97)) (26.0.3)\n",
      "Requirement already satisfied: referencing==0.35.1 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 98)) (0.35.1)\n",
      "Requirement already satisfied: requests==2.31.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 99)) (2.31.0)\n",
      "Requirement already satisfied: rfc3339-validator==0.1.4 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 100)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator==0.1.1 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 101)) (0.1.1)\n",
      "Requirement already satisfied: rich==13.7.1 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 102)) (13.7.1)\n",
      "Requirement already satisfied: rpds-py==0.18.1 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 103)) (0.18.1)\n",
      "Requirement already satisfied: Send2Trash==1.8.3 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 104)) (1.8.3)\n",
      "Requirement already satisfied: six==1.16.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 105)) (1.16.0)\n",
      "Requirement already satisfied: sniffio==1.3.1 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 106)) (1.3.1)\n",
      "Requirement already satisfied: soupsieve==2.5 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 107)) (2.5)\n",
      "Requirement already satisfied: stack-data==0.6.3 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 108)) (0.6.3)\n",
      "Requirement already satisfied: tensorboard==2.16.2 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 109)) (2.16.2)\n",
      "Requirement already satisfied: tensorboard-data-server==0.7.2 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 110)) (0.7.2)\n",
      "Requirement already satisfied: tensorflow==2.16.1 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 111)) (2.16.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.37.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 112)) (0.37.0)\n",
      "Requirement already satisfied: termcolor==2.4.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 113)) (2.4.0)\n",
      "Requirement already satisfied: terminado==0.18.1 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 114)) (0.18.1)\n",
      "Requirement already satisfied: tinycss2==1.3.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 115)) (1.3.0)\n",
      "Requirement already satisfied: tornado==6.4 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 116)) (6.4)\n",
      "Requirement already satisfied: tqdm==4.66.4 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 117)) (4.66.4)\n",
      "Requirement already satisfied: traitlets==5.14.3 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 118)) (5.14.3)\n",
      "Requirement already satisfied: types-python-dateutil==2.9.0.20240316 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 119)) (2.9.0.20240316)\n",
      "Requirement already satisfied: typing_extensions==4.11.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 120)) (4.11.0)\n",
      "Requirement already satisfied: tzdata==2024.1 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 121)) (2024.1)\n",
      "Requirement already satisfied: uri-template==1.3.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 122)) (1.3.0)\n",
      "Requirement already satisfied: urllib3==2.2.1 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 123)) (2.2.1)\n",
      "Requirement already satisfied: wcwidth==0.2.13 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 124)) (0.2.13)\n",
      "Requirement already satisfied: webcolors==1.13 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 125)) (1.13)\n",
      "Requirement already satisfied: webencodings==0.5.1 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 126)) (0.5.1)\n",
      "Requirement already satisfied: websocket-client==1.8.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 127)) (1.8.0)\n",
      "Requirement already satisfied: Werkzeug==3.0.3 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 128)) (3.0.3)\n",
      "Requirement already satisfied: widgetsnbextension==4.0.10 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 129)) (4.0.10)\n",
      "Requirement already satisfied: wrapt==1.16.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 130)) (1.16.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./venv/lib/python3.11/site-packages (from astunparse==1.6.3->-r requirements.txt (line 8)) (0.43.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in ./venv/lib/python3.11/site-packages (from tensorboard==2.16.2->-r requirements.txt (line 109)) (65.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af1d85e-67af-4d5d-8cc0-c1fadd80ad39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b09be44d-b9fa-4357-8797-e9daab2ffa04",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret initializer identifier: {'module': 'keras.initializers', 'class_name': 'Orthogonal', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels/model_9.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Image Caption Generator/venv/lib/python3.11/site-packages/keras/src/saving/saving_api.py:183\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[1;32m    177\u001b[0m         filepath,\n\u001b[1;32m    178\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[1;32m    180\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[1;32m    181\u001b[0m     )\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_h5_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model_from_hdf5\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    191\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Image Caption Generator/venv/lib/python3.11/site-packages/keras/src/legacy/saving/legacy_h5_format.py:133\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    130\u001b[0m model_config \u001b[38;5;241m=\u001b[39m json_utils\u001b[38;5;241m.\u001b[39mdecode(model_config)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m saving_options\u001b[38;5;241m.\u001b[39mkeras_option_scope(use_legacy_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 133\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43msaving_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# set weights\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     load_weights_from_hdf5_group(f[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m], model)\n",
      "File \u001b[0;32m~/Documents/Image Caption Generator/venv/lib/python3.11/site-packages/keras/src/legacy/saving/saving_utils.py:85\u001b[0m, in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# TODO(nkovela): Swap find and replace args during Keras 3.0 release\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Replace keras refs with keras\u001b[39;00m\n\u001b[1;32m     83\u001b[0m config \u001b[38;5;241m=\u001b[39m _find_replace_nested_dict(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mserialization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODULE_OBJECTS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mALL_OBJECTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprintable_module_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlayer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Image Caption Generator/venv/lib/python3.11/site-packages/keras/src/legacy/saving/serialization.py:495\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    490\u001b[0m cls_config \u001b[38;5;241m=\u001b[39m _find_replace_nested_dict(\n\u001b[1;32m    491\u001b[0m     cls_config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    492\u001b[0m )\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom_objects\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m arg_spec\u001b[38;5;241m.\u001b[39margs:\n\u001b[0;32m--> 495\u001b[0m     deserialized_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcls_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mobject_registration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGLOBAL_CUSTOM_OBJECTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m object_registration\u001b[38;5;241m.\u001b[39mCustomObjectScope(custom_objects):\n",
      "File \u001b[0;32m~/Documents/Image Caption Generator/venv/lib/python3.11/site-packages/keras/src/models/model.py:517\u001b[0m, in \u001b[0;36mModel.from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_functional_config \u001b[38;5;129;01mand\u001b[39;00m revivable_as_functional:\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;66;03m# Revive Functional model\u001b[39;00m\n\u001b[1;32m    514\u001b[0m     \u001b[38;5;66;03m# (but not Functional subclasses with a custom __init__)\u001b[39;00m\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional_from_config\n\u001b[0;32m--> 517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunctional_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;66;03m# Either the model has a custom __init__, or the config\u001b[39;00m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;66;03m# does not contain all the information necessary to\u001b[39;00m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;66;03m# revive a Functional model. This happens when the user creates\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;66;03m# In this case, we fall back to provide all config into the\u001b[39;00m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;66;03m# constructor of the class.\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/Image Caption Generator/venv/lib/python3.11/site-packages/keras/src/models/functional.py:517\u001b[0m, in \u001b[0;36mfunctional_from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;66;03m# First, we create all layers and enqueue nodes to be processed\u001b[39;00m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_data \u001b[38;5;129;01min\u001b[39;00m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayers\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 517\u001b[0m     \u001b[43mprocess_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;66;03m# Then we process nodes in order of layer depth.\u001b[39;00m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;66;03m# Nodes that cannot yet be processed (if the inbound node\u001b[39;00m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;66;03m# does not yet exist) are re-enqueued, and the process\u001b[39;00m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;66;03m# is repeated until all nodes are processed.\u001b[39;00m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m unprocessed_nodes:\n",
      "File \u001b[0;32m~/Documents/Image Caption Generator/venv/lib/python3.11/site-packages/keras/src/models/functional.py:497\u001b[0m, in \u001b[0;36mfunctional_from_config.<locals>.process_layer\u001b[0;34m(layer_data)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# Instantiate layer.\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m layer_data:\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;66;03m# Legacy format deserialization (no \"module\" key)\u001b[39;00m\n\u001b[1;32m    496\u001b[0m     \u001b[38;5;66;03m# used for H5 and SavedModel formats\u001b[39;00m\n\u001b[0;32m--> 497\u001b[0m     layer \u001b[38;5;241m=\u001b[39m \u001b[43msaving_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    501\u001b[0m     layer \u001b[38;5;241m=\u001b[39m serialization_lib\u001b[38;5;241m.\u001b[39mdeserialize_keras_object(\n\u001b[1;32m    502\u001b[0m         layer_data, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects\n\u001b[1;32m    503\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Image Caption Generator/venv/lib/python3.11/site-packages/keras/src/legacy/saving/saving_utils.py:85\u001b[0m, in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# TODO(nkovela): Swap find and replace args during Keras 3.0 release\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Replace keras refs with keras\u001b[39;00m\n\u001b[1;32m     83\u001b[0m config \u001b[38;5;241m=\u001b[39m _find_replace_nested_dict(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mserialization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODULE_OBJECTS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mALL_OBJECTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprintable_module_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlayer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Image Caption Generator/venv/lib/python3.11/site-packages/keras/src/legacy/saving/serialization.py:504\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    503\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m object_registration\u001b[38;5;241m.\u001b[39mCustomObjectScope(custom_objects):\n\u001b[0;32m--> 504\u001b[0m             deserialized_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcls_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;66;03m# Then `cls` may be a function returning a class.\u001b[39;00m\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;66;03m# in this case by convention `config` holds\u001b[39;00m\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;66;03m# the kwargs of the function.\u001b[39;00m\n\u001b[1;32m    509\u001b[0m     custom_objects \u001b[38;5;241m=\u001b[39m custom_objects \u001b[38;5;129;01mor\u001b[39;00m {}\n",
      "File \u001b[0;32m~/Documents/Image Caption Generator/venv/lib/python3.11/site-packages/keras/src/layers/rnn/lstm.py:669\u001b[0m, in \u001b[0;36mLSTM.from_config\u001b[0;34m(cls, config)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_config\u001b[39m(\u001b[38;5;28mcls\u001b[39m, config):\n\u001b[0;32m--> 669\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Image Caption Generator/venv/lib/python3.11/site-packages/keras/src/layers/rnn/lstm.py:463\u001b[0m, in \u001b[0;36mLSTM.__init__\u001b[0;34m(self, units, activation, recurrent_activation, use_bias, kernel_initializer, recurrent_initializer, bias_initializer, unit_forget_bias, kernel_regularizer, recurrent_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, recurrent_constraint, bias_constraint, dropout, recurrent_dropout, seed, return_sequences, return_state, go_backwards, stateful, unroll, use_cudnn, **kwargs)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    437\u001b[0m     units,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    462\u001b[0m ):\n\u001b[0;32m--> 463\u001b[0m     cell \u001b[38;5;241m=\u001b[39m \u001b[43mLSTMCell\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43munits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactivation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrecurrent_activation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecurrent_activation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkernel_initializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel_initializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43munit_forget_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munit_forget_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrecurrent_initializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecurrent_initializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbias_initializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias_initializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkernel_regularizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel_regularizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrecurrent_regularizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecurrent_regularizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbias_regularizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias_regularizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkernel_constraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel_constraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrecurrent_constraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecurrent_constraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbias_constraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias_constraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrecurrent_dropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecurrent_dropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrainable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlstm_cell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimplementation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimplementation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    487\u001b[0m         cell,\n\u001b[1;32m    488\u001b[0m         return_sequences\u001b[38;5;241m=\u001b[39mreturn_sequences,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    495\u001b[0m     )\n\u001b[1;32m    496\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_spec \u001b[38;5;241m=\u001b[39m InputSpec(ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Image Caption Generator/venv/lib/python3.11/site-packages/keras/src/layers/rnn/lstm.py:122\u001b[0m, in \u001b[0;36mLSTMCell.__init__\u001b[0;34m(self, units, activation, recurrent_activation, use_bias, kernel_initializer, recurrent_initializer, bias_initializer, unit_forget_bias, kernel_regularizer, recurrent_regularizer, bias_regularizer, kernel_constraint, recurrent_constraint, bias_constraint, dropout, recurrent_dropout, seed, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_bias \u001b[38;5;241m=\u001b[39m use_bias\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_initializer \u001b[38;5;241m=\u001b[39m initializers\u001b[38;5;241m.\u001b[39mget(kernel_initializer)\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurrent_initializer \u001b[38;5;241m=\u001b[39m \u001b[43minitializers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecurrent_initializer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias_initializer \u001b[38;5;241m=\u001b[39m initializers\u001b[38;5;241m.\u001b[39mget(bias_initializer)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_regularizer \u001b[38;5;241m=\u001b[39m regularizers\u001b[38;5;241m.\u001b[39mget(kernel_regularizer)\n",
      "File \u001b[0;32m~/Documents/Image Caption Generator/venv/lib/python3.11/site-packages/keras/src/initializers/__init__.py:118\u001b[0m, in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    119\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not interpret initializer identifier: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midentifier\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    120\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Could not interpret initializer identifier: {'module': 'keras.initializers', 'class_name': 'Orthogonal', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('models/model_9.h5', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22ad75a-6c62-4f5e-861c-b844a0a6f1d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1c0f6b-f428-4357-bb3d-e46213b1740d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
