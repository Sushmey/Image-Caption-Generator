{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f077fc1-8608-412b-84b3-c4e2505cdcd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: TensorFlow in ./venv/lib/python3.11/site-packages (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./venv/lib/python3.11/site-packages (from TensorFlow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./venv/lib/python3.11/site-packages (from TensorFlow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in ./venv/lib/python3.11/site-packages (from TensorFlow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./venv/lib/python3.11/site-packages (from TensorFlow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./venv/lib/python3.11/site-packages (from TensorFlow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in ./venv/lib/python3.11/site-packages (from TensorFlow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./venv/lib/python3.11/site-packages (from TensorFlow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in ./venv/lib/python3.11/site-packages (from TensorFlow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./venv/lib/python3.11/site-packages (from TensorFlow) (3.3.0)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.11/site-packages (from TensorFlow) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./venv/lib/python3.11/site-packages (from TensorFlow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./venv/lib/python3.11/site-packages (from TensorFlow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.11/site-packages (from TensorFlow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./venv/lib/python3.11/site-packages (from TensorFlow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./venv/lib/python3.11/site-packages (from TensorFlow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./venv/lib/python3.11/site-packages (from TensorFlow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./venv/lib/python3.11/site-packages (from TensorFlow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./venv/lib/python3.11/site-packages (from TensorFlow) (1.63.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in ./venv/lib/python3.11/site-packages (from TensorFlow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in ./venv/lib/python3.11/site-packages (from TensorFlow) (3.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./venv/lib/python3.11/site-packages (from TensorFlow) (0.37.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in ./venv/lib/python3.11/site-packages (from TensorFlow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./venv/lib/python3.11/site-packages (from astunparse>=1.6.0->TensorFlow) (0.43.0)\n",
      "Requirement already satisfied: rich in ./venv/lib/python3.11/site-packages (from keras>=3.0.0->TensorFlow) (13.7.1)\n",
      "Requirement already satisfied: namex in ./venv/lib/python3.11/site-packages (from keras>=3.0.0->TensorFlow) (0.0.8)\n",
      "Requirement already satisfied: optree in ./venv/lib/python3.11/site-packages (from keras>=3.0.0->TensorFlow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->TensorFlow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->TensorFlow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->TensorFlow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->TensorFlow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./venv/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->TensorFlow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./venv/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->TensorFlow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./venv/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->TensorFlow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./venv/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->TensorFlow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./venv/lib/python3.11/site-packages (from rich->keras>=3.0.0->TensorFlow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./venv/lib/python3.11/site-packages (from rich->keras>=3.0.0->TensorFlow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./venv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->TensorFlow) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: Keras in ./venv/lib/python3.11/site-packages (3.3.3)\n",
      "Requirement already satisfied: absl-py in ./venv/lib/python3.11/site-packages (from Keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.11/site-packages (from Keras) (1.26.4)\n",
      "Requirement already satisfied: rich in ./venv/lib/python3.11/site-packages (from Keras) (13.7.1)\n",
      "Requirement already satisfied: namex in ./venv/lib/python3.11/site-packages (from Keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in ./venv/lib/python3.11/site-packages (from Keras) (3.11.0)\n",
      "Requirement already satisfied: optree in ./venv/lib/python3.11/site-packages (from Keras) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in ./venv/lib/python3.11/site-packages (from Keras) (0.3.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in ./venv/lib/python3.11/site-packages (from optree->Keras) (4.11.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./venv/lib/python3.11/site-packages (from rich->Keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./venv/lib/python3.11/site-packages (from rich->Keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./venv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->Keras) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pillow in ./venv/lib/python3.11/site-packages (10.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: NumPy in ./venv/lib/python3.11/site-packages (1.26.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.11/site-packages (4.66.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: jupyterlab in ./venv/lib/python3.11/site-packages (4.1.8)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in ./venv/lib/python3.11/site-packages (from jupyterlab) (2.0.4)\n",
      "Requirement already satisfied: httpx>=0.25.0 in ./venv/lib/python3.11/site-packages (from jupyterlab) (0.27.0)\n",
      "Requirement already satisfied: ipykernel>=6.5.0 in ./venv/lib/python3.11/site-packages (from jupyterlab) (6.29.4)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in ./venv/lib/python3.11/site-packages (from jupyterlab) (3.1.4)\n",
      "Requirement already satisfied: jupyter-core in ./venv/lib/python3.11/site-packages (from jupyterlab) (5.7.2)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in ./venv/lib/python3.11/site-packages (from jupyterlab) (2.2.5)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in ./venv/lib/python3.11/site-packages (from jupyterlab) (2.14.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in ./venv/lib/python3.11/site-packages (from jupyterlab) (2.27.1)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in ./venv/lib/python3.11/site-packages (from jupyterlab) (0.2.4)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.11/site-packages (from jupyterlab) (24.0)\n",
      "Requirement already satisfied: tornado>=6.2.0 in ./venv/lib/python3.11/site-packages (from jupyterlab) (6.4)\n",
      "Requirement already satisfied: traitlets in ./venv/lib/python3.11/site-packages (from jupyterlab) (5.14.3)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.11/site-packages (from httpx>=0.25.0->jupyterlab) (4.3.0)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.11/site-packages (from httpx>=0.25.0->jupyterlab) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.11/site-packages (from httpx>=0.25.0->jupyterlab) (1.0.5)\n",
      "Requirement already satisfied: idna in ./venv/lib/python3.11/site-packages (from httpx>=0.25.0->jupyterlab) (3.7)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.11/site-packages (from httpx>=0.25.0->jupyterlab) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab) (0.14.0)\n",
      "Requirement already satisfied: appnope in ./venv/lib/python3.11/site-packages (from ipykernel>=6.5.0->jupyterlab) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in ./venv/lib/python3.11/site-packages (from ipykernel>=6.5.0->jupyterlab) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in ./venv/lib/python3.11/site-packages (from ipykernel>=6.5.0->jupyterlab) (1.8.1)\n",
      "Requirement already satisfied: ipython>=7.23.1 in ./venv/lib/python3.11/site-packages (from ipykernel>=6.5.0->jupyterlab) (8.24.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in ./venv/lib/python3.11/site-packages (from ipykernel>=6.5.0->jupyterlab) (8.6.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in ./venv/lib/python3.11/site-packages (from ipykernel>=6.5.0->jupyterlab) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in ./venv/lib/python3.11/site-packages (from ipykernel>=6.5.0->jupyterlab) (1.6.0)\n",
      "Requirement already satisfied: psutil in ./venv/lib/python3.11/site-packages (from ipykernel>=6.5.0->jupyterlab) (5.9.8)\n",
      "Requirement already satisfied: pyzmq>=24 in ./venv/lib/python3.11/site-packages (from ipykernel>=6.5.0->jupyterlab) (26.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.11/site-packages (from jinja2>=3.0.3->jupyterlab) (2.1.5)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./venv/lib/python3.11/site-packages (from jupyter-core->jupyterlab) (4.2.1)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in ./venv/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (23.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in ./venv/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in ./venv/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.5.3)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in ./venv/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.16.4)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in ./venv/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (5.10.4)\n",
      "Requirement already satisfied: overrides>=5.0 in ./venv/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in ./venv/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.20.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in ./venv/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in ./venv/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in ./venv/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.0)\n",
      "Requirement already satisfied: babel>=2.10 in ./venv/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (2.15.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in ./venv/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (0.9.25)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in ./venv/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (4.22.0)\n",
      "Requirement already satisfied: requests>=2.31 in ./venv/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (2.31.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in ./venv/lib/python3.11/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (21.2.0)\n",
      "Requirement already satisfied: decorator in ./venv/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./venv/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.19.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in ./venv/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./venv/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (2.18.0)\n",
      "Requirement already satisfied: stack-data in ./venv/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.6.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in ./venv/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (4.11.0)\n",
      "Requirement already satisfied: pexpect>4.3 in ./venv/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (4.9.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./venv/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./venv/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./venv/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./venv/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (0.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.11/site-packages (from jupyter-client>=6.1.12->ipykernel>=6.5.0->jupyterlab) (2.9.0.post0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in ./venv/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in ./venv/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (6.0.1)\n",
      "Requirement already satisfied: rfc3339-validator in ./venv/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in ./venv/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in ./venv/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in ./venv/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (6.1.0)\n",
      "Requirement already satisfied: defusedxml in ./venv/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in ./venv/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in ./venv/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (3.0.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in ./venv/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.10.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in ./venv/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.1)\n",
      "Requirement already satisfied: tinycss2 in ./venv/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in ./venv/lib/python3.11/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.19.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.11/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.11/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab) (2.2.1)\n",
      "Requirement already satisfied: ptyprocess in ./venv/lib/python3.11/site-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->jupyterlab) (0.7.0)\n",
      "Requirement already satisfied: six>=1.9.0 in ./venv/lib/python3.11/site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.16.0)\n",
      "Requirement already satisfied: webencodings in ./venv/lib/python3.11/site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.5.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in ./venv/lib/python3.11/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.8.4)\n",
      "Requirement already satisfied: fqdn in ./venv/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (1.5.1)\n",
      "Requirement already satisfied: isoduration in ./venv/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in ./venv/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (2.4)\n",
      "Requirement already satisfied: uri-template in ./venv/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in ./venv/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (1.13)\n",
      "Requirement already satisfied: wcwidth in ./venv/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.2.13)\n",
      "Requirement already satisfied: cffi>=1.0.1 in ./venv/lib/python3.11/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./venv/lib/python3.11/site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (2.5)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./venv/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./venv/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in ./venv/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.2.2)\n",
      "Requirement already satisfied: pycparser in ./venv/lib/python3.11/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (2.22)\n",
      "Requirement already satisfied: arrow>=0.15.0 in ./venv/lib/python3.11/site-packages (from isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in ./venv/lib/python3.11/site-packages (from arrow>=0.15.0->isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (2.9.0.20240316)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install TensorFlow\n",
    "!pip install Keras\n",
    "!pip install pillow\n",
    "!pip install NumPy\n",
    "!pip install tqdm\n",
    "!pip install jupyterlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ba0fa7-2fa3-4779-ad03-f915083961a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6197e28-9583-4ad1-a727-711260db0a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Keras-Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cb9485f-36ee-416a-892a-72bdab01167c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./venv/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in ./venv/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ef2adaf-63aa-4c88-8168-ee8be0e8a9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot-ng~=2.0.0 in ./venv/lib/python3.11/site-packages (2.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.1 in ./venv/lib/python3.11/site-packages (from pydot-ng~=2.0.0) (3.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pydot-ng~=2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb010f84-d435-451a-bc7b-0b0709c8f4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 01:35:37.765321: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1bfb7b0e1f34efc8b8f2709232866f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import string\n",
    "from pickle import dump\n",
    "from pickle import load\n",
    "from keras.applications.xception import Xception #to get pre-trained model Xception\n",
    "from keras.applications.xception import preprocess_input\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer #for text tokenization\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Concatenate\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense#Keras to build our CNN and LSTM\n",
    "from keras.layers import LSTM, Embedding, Dropout\n",
    "from tqdm.notebook import tqdm #to check loop progress\n",
    "tqdm().pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42add367-082b-483f-8066-089b7610793f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of descriptions = 8092\n",
      "Length of vocabulary =  8763\n"
     ]
    }
   ],
   "source": [
    "# Load the document file into memory\n",
    "def load_fp(filename):\n",
    "    # Open file to read\n",
    "    file = open(filename, 'r')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "# get all images with their captions\n",
    "def img_capt(filename):\n",
    "    file = load_fp(filename)\n",
    "    captions = file.split(\"\\n\")\n",
    "    descriptions ={}\n",
    "    for caption in captions[:-1]:\n",
    "        img, caption = caption.split(\"\\t\")\n",
    "        # print(f\"img {img} -- caption {caption}\")\n",
    "        if img[:-2] not in descriptions: # -2 because we are skipping the number at the end of the image name\n",
    "            descriptions[img[:-2]] = [caption]\n",
    "        else:\n",
    "            descriptions[img[:-2]].append(caption)\n",
    "    return descriptions\n",
    "\n",
    "#Data cleaning function will convert all upper case alphabets to lowercase, removing punctuations and words containing numbers\n",
    "def txt_clean(captions):\n",
    "    table = str.maketrans('','',string.punctuation)\n",
    "    for img,caps in captions.items():\n",
    "      for i,img_caption in enumerate(caps):\n",
    "        img_caption.replace(\"-\",\" \")\n",
    "        descp = img_caption.split()\n",
    "        #uppercase to lowercase\n",
    "        descp = [wrd.lower() for wrd in descp]\n",
    "        #remove punctuation from each token\n",
    "        descp = [wrd.translate(table) for wrd in descp]\n",
    "        #remove hanging 's and a\n",
    "        descp = [wrd for wrd in descp if(len(wrd)>1)] # len of `s is 2 but ' is removed in punctuation step\n",
    "        #remove words containing numbers with them\n",
    "        descp = [wrd for wrd in descp if(wrd.isalpha())]\n",
    "        #converting back to string\n",
    "        img_caption = \" \".join(descp)\n",
    "        captions[img][i]= img_caption\n",
    "        #print(f\"image {img} caption  - {captions[img][i]}\")\n",
    "    return captions\n",
    "\n",
    "def txt_vocab(descriptions):\n",
    "    # To build vocab of all unique words\n",
    "    vocab = set()\n",
    "    for key in descriptions.keys():\n",
    "        [vocab.update(d.split()) for d in descriptions[key]]\n",
    "        # for d in descriptions[key]:\n",
    "        #     [vocab.update(d.split())]\n",
    "        #     print(d.split())\n",
    "    return vocab\n",
    "\n",
    "#To save all descriptions in one file\n",
    "def save_descriptions(descriptions, filename):\n",
    "    lines = list()\n",
    "    for key, desc_list in descriptions.items():\n",
    "      for desc in desc_list:\n",
    "        lines.append(key + \"\\t\" + desc )\n",
    "        data = \"\\n\".join(lines)\n",
    "        file = open(filename,\"w\")\n",
    "        file.write(data)\n",
    "        file.close()\n",
    "# Set these path according to project folder in you system\n",
    "dataset_text = \"Flickr8k_text\"\n",
    "dataset_images = \"Flicker8k_Dataset\"\n",
    "#to prepare our text data\n",
    "filename = dataset_text + \"/\" + \"Flickr8k.token.txt\"\n",
    "#loading the file that contains all data\n",
    "#map them into descriptions dictionary \n",
    "descriptions = img_capt(filename)\n",
    "print(\"Length of descriptions =\" ,len(descriptions))\n",
    "#cleaning the descriptions\n",
    "clean_descriptions = txt_clean(descriptions)\n",
    "#to build vocabulary\n",
    "vocabulary = txt_vocab(clean_descriptions)\n",
    "print(\"Length of vocabulary = \", len(vocabulary))\n",
    "#saving all descriptions in one file\n",
    "save_descriptions(clean_descriptions, \"descriptions.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c75ea230-1c6c-45a5-98fa-ec85be14dd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set SSL \n",
    "\n",
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "169571d7-81e5-4388-b6dc-98151caa5eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(dirc):\n",
    "        model = Xception( include_top=False, pooling='avg' )\n",
    "        features = {}\n",
    "        for pic in tqdm(os.listdir(dirc)):\n",
    "                   file = dirc + \"/\" + pic\n",
    "                   image = Image.open(file)\n",
    "                   image = image.resize((299,299))\n",
    "                   image = np.expand_dims(image, axis=0)\n",
    "                   #image = preprocess_input(image)\n",
    "                   image = image/127.5 # Image normalization 255/2 = 127.5\n",
    "                   image = image - 1.0 # Converting it to between range -1 to 1\n",
    "                   feature = model.predict(image)\n",
    "                   features[pic] = feature\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "593c1014-ecb2-474b-af5a-c4ae68b53bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run only once\n",
    "\n",
    "# #2048 feature vector\n",
    "# features = extract_features(dataset_images)\n",
    "# dump(features, open(\"features.p\",\"wb\"))\n",
    "# #to directly load the features from the pickle file.\n",
    "# features = load(open(\"features.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78569cbe-5072-44ef-babc-ea9f7eb012ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' child in pink dress is climbing up set of stairs in an entry way ', ' girl going into wooden building ', ' little girl climbing into wooden playhouse ', ' little girl climbing the stairs to her playhouse ', ' little girl in pink dress going into wooden cabin ']\n"
     ]
    }
   ],
   "source": [
    "#load the data\n",
    "def load_photos(filename):\n",
    "    file = load_fp(filename)\n",
    "    photos = file.split(\"\\n\")[:-1]\n",
    "    return photos\n",
    "def load_clean_descriptions(filename, photos):\n",
    "    #loading clean_descriptions\n",
    "    file = load_fp(filename)\n",
    "    descriptions = {}\n",
    "    for line in file.split(\"\\n\"):\n",
    "        words = line.split()\n",
    "        if len(words)<2: # To skip img desc pair with no desc since len of list will be just 1 then. But it should be <2  not <1\n",
    "            continue\n",
    "        image, image_caption = words[0], words[1:]\n",
    "        if image in photos: \n",
    "            if image not in descriptions:\n",
    "                descriptions[image] = []\n",
    "            desc = f' {\" \".join(image_caption)} '\n",
    "            # desc = ' ' + \" \".join(image_caption) + ' '\n",
    "            # print(desc)\n",
    "            descriptions[image].append(desc)\n",
    "    print(descriptions[\"1000268201_693b08cb0e.jpg\"])            \n",
    "    return descriptions\n",
    "def load_features(photos):\n",
    "    #loading all featuresq\n",
    "    all_features = load(open(\"features.p\",\"rb\"))\n",
    "    #selecting only needed features\n",
    "    features = {k:all_features[k] for k in photos}\n",
    "    return features\n",
    "filename = dataset_text + \"/\" + \"Flickr_8k.trainImages.txt\"\n",
    "#train = loading_data(filename)\n",
    "train_imgs = load_photos(filename)\n",
    "train_descriptions = load_clean_descriptions(\"descriptions.txt\", train_imgs)\n",
    "train_features = load_features(train_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfa2b301-1095-482f-a6df-2abaa54b8634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7577\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "#convert dictionary to clear list of descriptions\n",
    "def dict_to_list(descriptions):\n",
    "    all_desc = []\n",
    "    for key in descriptions.keys():\n",
    "       [all_desc.append(d) for d in descriptions[key]]\n",
    "    # print(f\"Length of all_desc {len(all_desc)}\")    \n",
    "    return all_desc\n",
    "#creating tokenizer class\n",
    "#this will vectorise text corpus\n",
    "#each integer will represent token in dictionary\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "def create_tokenizer(descriptions):\n",
    "    desc_list = dict_to_list(descriptions)\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(desc_list)\n",
    "    return tokenizer\n",
    "# give each word an index, and store that into tokenizer.p pickle file\n",
    "tokenizer = create_tokenizer(train_descriptions)\n",
    "dump(tokenizer, open('tokenizer.p', 'wb'))\n",
    "# print(tokenizer.word_index)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(vocab_size) #The size of our vocabulary is 7577 words.\n",
    "#calculate maximum length of descriptions to decide the model structure parameters.\n",
    "def max_length(descriptions):\n",
    "    desc_list = dict_to_list(descriptions)\n",
    "    return max(len(d.split()) for d in desc_list)\n",
    "max_length = max_length(descriptions)\n",
    "print(max_length) #Max_length of description is 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d7c5c22-cdfc-403a-8289-28667b467de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feature' 'feature' 'feature' 'feature' 'feature' 'feature' 'feature'\n",
      " 'feature' 'feature' 'feature' 'feature' 'feature' 'feature']\n",
      "\n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0   40]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0   40    1]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0   40    1   85]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    40    1   85  167]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0   40\n",
      "     1   85  167    4]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0   40    1\n",
      "    85  167    4  115]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0   40    1   85\n",
      "   167    4  115   53]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0   40    1   85  167\n",
      "     4  115   53  391]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0   40    1   85  167    4\n",
      "   115   53  391    9]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0   40    1   85  167    4  115\n",
      "    53  391    9  392]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0   40    1   85  167    4  115   53\n",
      "   391    9  392    1]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0   40    1   85  167    4  115   53  391\n",
      "     9  392    1   25]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0   40    1   85  167    4  115   53  391    9\n",
      "   392    1   25 4472]]\n",
      "\n",
      " [[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(13,) (13, 32) (13, 7577)\n"
     ]
    }
   ],
   "source": [
    "seq = tokenizer.texts_to_sequences([' child in pink dress is climbing up set of stairs in an entry way '])[0]\n",
    "x_1, x_2, y = list(), list(), list()\n",
    "for i in range(1, len(seq)):\n",
    "    # divide into input and output pair\n",
    "    in_seq, out_seq = seq[:i], seq[i]\n",
    "    # pad input sequence\n",
    "    in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
    "    # encode output sequence\n",
    "    out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "    # store\n",
    "    x_1.append(\"feature\")\n",
    "    x_2.append(in_seq)\n",
    "    y.append(out_seq)\n",
    "x_1, x_2, y = np.array(x_1), np.array(x_2), np.array(y)\n",
    "print(f\"{x_1}\\n\\n{x_2}\\n\\n {y}\")\n",
    "print(x_1.shape, x_2.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c344a469-1bd7-45c6-b4ba-8327392af20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37, 2048) (37, 32) (37, 7577)\n"
     ]
    }
   ],
   "source": [
    "#data generator, used by model.fit_generator()\n",
    "def data_generator(descriptions, features, tokenizer, max_length):\n",
    "    while True:\n",
    "        for key, description_list in descriptions.items():\n",
    "            #retrieve photo features\n",
    "            feature = features[key][0]\n",
    "            inp_image, inp_seq, op_word = create_sequences(tokenizer, max_length, description_list, feature)\n",
    "            yield ((inp_image, inp_seq), op_word)\n",
    "def create_sequences(tokenizer, max_length, desc_list, feature):\n",
    "    x_1, x_2, y = list(), list(), list()\n",
    "    # move through each description for the image\n",
    "    for desc in desc_list:\n",
    "        # encode the sequence\n",
    "        seq = tokenizer.texts_to_sequences([desc])[0]\n",
    "        # divide one sequence into various X,y pairs\n",
    "        for i in range(1, len(seq)):\n",
    "            # divide into input and output pair\n",
    "            in_seq, out_seq = seq[:i], seq[i]\n",
    "            # pad input sequence\n",
    "            in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
    "            # encode output sequence\n",
    "            out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "            # store\n",
    "            x_1.append(feature)\n",
    "            x_2.append(in_seq)\n",
    "            y.append(out_seq)\n",
    "    return np.array(x_1), np.array(x_2), np.array(y)\n",
    "#To check the shape of the input and output for your model\n",
    "[a,b],c = next(data_generator(descriptions, train_features, tokenizer, max_length))\n",
    "print(a.shape, b.shape, c.shape)\n",
    "#((47, 2048), (47, 32), (47, 7577))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9837719a-afed-4959-8fa6-7ab63a7889dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "# define the captioning model\n",
    "def define_model(vocab_size, max_length):\n",
    "    # features from the CNN model compressed from 2048 to 256 nodes\n",
    "    inputs1 = Input(shape=(2048,))\n",
    "    fe1 = Dropout(0.5)(inputs1)\n",
    "    fe2 = Dense(256, activation='relu')(fe1)\n",
    "    # LSTM sequence model\n",
    "    inputs2 = Input(shape=(max_length,))\n",
    "    se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
    "    se2 = Dropout(0.5)(se1)\n",
    "    se3 = LSTM(256)(se2)\n",
    "    # Merging both models\n",
    "    decoder1 = Concatenate()([fe2, se3])\n",
    "    decoder2 = Dense(256, activation='relu')(decoder1)\n",
    "    outputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
    "    # merge it [image, seq] [word]\n",
    "    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    # summarize model\n",
    "    print(model.summary())\n",
    "    plot_model(model, to_file='model.png', show_shapes=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec5f278-2975-421b-8057-57ed917afda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  6000\n",
      "Descriptions: train= 6000\n",
      "Photos: train= 6000\n",
      "Vocabulary Size: 7577\n",
      "Description Length:  32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,939,712</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ not_equal_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7577</span>)      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,947,289</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │  \u001b[38;5;34m1,939,712\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m524,544\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m525,312\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ not_equal_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m131,328\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7577\u001b[0m)      │  \u001b[38;5;34m1,947,289\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,068,185</span> (19.33 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,068,185\u001b[0m (19.33 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,068,185</span> (19.33 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,068,185\u001b[0m (19.33 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n",
      "model <Functional name=functional_5, built=True>\n",
      "\u001b[1m6000/6000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m765s\u001b[0m 127ms/step - loss: 5.4091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6000/6000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m953s\u001b[0m 159ms/step - loss: 4.0154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6000/6000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1084s\u001b[0m 181ms/step - loss: 3.6392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1438/6000\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20:23\u001b[0m 268ms/step - loss: 3.4596"
     ]
    }
   ],
   "source": [
    "# train our model\n",
    "print('Dataset: ', len(train_imgs))\n",
    "print('Descriptions: train=', len(train_descriptions))\n",
    "print('Photos: train=', len(train_features))\n",
    "print('Vocabulary Size:', vocab_size)\n",
    "print('Description Length: ', max_length)\n",
    "model = define_model(vocab_size, max_length)\n",
    "print(f\"model {model}\")\n",
    "epochs = 10\n",
    "steps = len(train_descriptions)\n",
    "# creating a directory named models to save our models\n",
    "# os.mkdir(\"models\")\n",
    "for i in range(epochs):\n",
    "    generator = data_generator(train_descriptions, train_features, tokenizer, max_length)\n",
    "    #model.fit([x1,x2],y)\n",
    "    model.fit(generator, epochs=1, steps_per_epoch=steps, verbose=1)\n",
    "    model.save(f\"models/model_{i}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51161abe-2eaf-482a-a353-43c7a918da9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cce2a6-44a0-4574-ab14-8e994f28490a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
